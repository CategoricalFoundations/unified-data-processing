\documentclass{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{tikz}
\usetikzlibrary{positioning}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}

\title{Tensor Network Reduction and Approximation\\
\large Supplementary Material for PODS 2026 Submission}
\author{Anonymous}
\date{}

\begin{document}

\maketitle

\begin{abstract}
This document provides the complete reduction from tensor network contraction 
order optimization to the Minimum Fill-In problem, establishing the 
approximation bound in Theorem 8.5.
\end{abstract}

\section{Background}

\begin{definition}[Tensor Network]
A tensor network is a graph $G = (V, E)$ where:
\begin{itemize}
    \item Each vertex $v \in V$ represents a tensor $T_v$
    \item Each edge $e = (u, v) \in E$ represents a shared index to be contracted
    \item The contraction order determines computational complexity
\end{itemize}
\end{definition}

\begin{definition}[Minimum Fill-In]
Given a graph $G = (V, E)$, find the minimum number of edges to add such that 
$G$ becomes chordal (every cycle of length $\geq 4$ has a chord).
\end{definition}

\section{Reduction}

\begin{theorem}[Theorem 8.5]
The optimal tensor network contraction order problem admits an 
$O(\log n / \log \log n)$-approximation via reduction from Minimum Fill-In.
\end{theorem}

\begin{proof}
We establish a polynomial-time reduction from tensor network contraction to 
Minimum Fill-In, then apply known approximation results.

\textbf{Step 1: Construct Fill-In Instance}

Given tensor network $G = (V, E)$:
\begin{enumerate}
    \item Create graph $G' = (V, E)$ (same graph)
    \item Each tensor contraction corresponds to eliminating a vertex
    \item Fill-in edges correspond to intermediate tensors created
\end{enumerate}

\textbf{Step 2: Correspondence}

\begin{lemma}
A contraction order with cost $C$ corresponds to a fill-in with at most $C$ edges.
\end{lemma}

\begin{proof}
When contracting tensors $T_u$ and $T_v$:
\begin{itemize}
    \item All indices of $T_u$ not shared with $T_v$ become indices of result
    \item This is equivalent to eliminating $u$ and adding edges between 
          all neighbors of $u$ (if not already present)
    \item The number of new edges equals the fill-in at this step
\end{itemize}
\end{proof}

\textbf{Step 3: Apply Approximation}

The Minimum Fill-In problem admits an $O(\log n / \log \log n)$-approximation 
algorithm (Natanzon, Shamir, and Sharan, 2000).

By the correspondence above, this yields the same approximation factor for 
tensor network contraction order.
\end{proof}

\section{Application to Join Ordering}

The tensor network formulation applies to join ordering:

\begin{itemize}
    \item Each relation $R_i$ is a tensor
    \item Shared attributes are contracted indices
    \item Join order corresponds to contraction order
\end{itemize}

\begin{corollary}
Optimal join ordering admits an $O(\log n / \log \log n)$-approximation for 
$n$ relations.
\end{corollary}

\section{AMS Sketch Bounds}

\begin{theorem}[Theorem 8.6: Space-Time Tradeoff]
AMS sketches achieve $O(k \cdot \epsilon^{-2} \cdot \log |D|)$ space with 
failure probability $\delta = 2^{-k}$.
\end{theorem}

\begin{proof}
The AMS sketch maintains $k$ independent estimates, each using 
$O(\epsilon^{-2} \cdot \log |D|)$ space:
\begin{itemize}
    \item Each estimate uses $O(\epsilon^{-2})$ hash buckets
    \item Each bucket stores $O(\log |D|)$ bits
    \item Taking median of $k$ estimates reduces failure probability to $2^{-\Omega(k)}$
\end{itemize}

By Chernoff bounds, the median estimate has relative error $\leq \epsilon$ with 
probability $\geq 1 - 2^{-k}$.
\end{proof}

\end{document}
